{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654856102005,
     "user": {
      "displayName": "Bhagyesh Gaikwad",
      "userId": "02667505171407796611"
     },
     "user_tz": 420
    },
    "id": "C1lQ6Z80F0yK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure that the below files are uploaded in the temorary runtime in Google Collab or in the  same directory as the notebook if you are running via Jupyter.\n",
    "\n",
    "You can change the variables 'train_file' and 'test_file' with your own file names which should be in the csv format <PC,Memory address,LoadValue> or the original format eg: 0x7f64b4765e1f: R 0x7f64b4791e68, 0x000000000000000e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_pinatrace.out'\n",
    "test_file = 'test_pinatrace.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_format(fname):\n",
    "\n",
    "    with open(fname, 'r+') as f:\n",
    "        text = f.read()\n",
    "        text = re.sub(' ','',text)\n",
    "        text = re.sub(':',',',text)\n",
    "        text = re.sub('R','', text)\n",
    "        text = re.sub('#eof','',text)\n",
    "\n",
    "        f.seek(0)\n",
    "        f.write(text)\n",
    "        f.truncate()\n",
    "        \n",
    "def map(Y):\n",
    "    mapping={v:k for k,v in enumerate(set(Y))}\n",
    "    Y1=[mapping[y] for y in Y]\n",
    "    return np.array(Y1)\n",
    "\n",
    "def get_data(fname):\n",
    "    csv_format(fname)\n",
    "    df = pd.read_csv(fname, sep=\",\", header=None, names=[\"PC\", \"MemAdd\", \"Val\"], converters={0:partial(int, base=16),\n",
    "                                                                                            1:partial(int, base=16),\n",
    "                                                                                            2:partial(int, base=16)})\n",
    "    p,m,v = df.nunique()\n",
    "    PC = df['PC'].to_numpy()\n",
    "    MemAdd = df['MemAdd'].to_numpy()\n",
    "    Val = df['Val'].to_numpy()\n",
    "    PC = map(list(PC))\n",
    "    MemAdd = map(list(MemAdd))\n",
    "    return PC, MemAdd, Val, p, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1503,
     "status": "ok",
     "timestamp": 1654856103504,
     "user": {
      "displayName": "Bhagyesh Gaikwad",
      "userId": "02667505171407796611"
     },
     "user_tz": 420
    },
    "id": "K20673XWF0yN"
   },
   "outputs": [],
   "source": [
    "train_PC, train_MemAdd, train_Val, train_unique_PCs, train_unique_memadds = get_data(train_file)\n",
    "\n",
    "test_PC, test_MemAdd, test_Val, test_unique_PCs, test_unique_memadds = get_data(test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Baseline : Last Value Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline_predictor(PC, MemAdd, Val, p, m):\n",
    "    correct = 0\n",
    "    total_vals = Val.shape[0]\n",
    "    p_dic = {}\n",
    "            \n",
    "    for i in range(total_vals):\n",
    "        if (PC[i], MemAdd[i]) not in p_dic.keys():\n",
    "            p_dic[(PC[i], MemAdd[i])] = 0\n",
    "        if p_dic[(PC[i], MemAdd[i])] == Val[i]:\n",
    "            correct +=1\n",
    "        else:\n",
    "            p_dic[(PC[i], MemAdd[i])] = Val[i]\n",
    "                \n",
    "    return (correct/total_vals)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1654856104155,
     "user": {
      "displayName": "Bhagyesh Gaikwad",
      "userId": "02667505171407796611"
     },
     "user_tz": 420
    },
    "id": "_yaj9UIhF0yP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy for baseline Last Value predictor is 63.35\n"
     ]
    }
   ],
   "source": [
    "train_accu = baseline_predictor(train_PC, train_MemAdd, train_Val, train_unique_PCs, train_unique_memadds)\n",
    "print(\"The train accuracy for baseline Last Value predictor is {:.2f}\".format(train_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy for baseline Last Value predictor is 64.08\n"
     ]
    }
   ],
   "source": [
    "test_accu = baseline_predictor(test_PC, test_MemAdd, test_Val, test_unique_PCs, test_unique_memadds)\n",
    "print(\"The test accuracy for baseline Last Value predictor is {:.2f}\".format(test_accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor for Last n load values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_n_vals(PC, MemAdd, Val, p, m, total_vals,n):\n",
    "    correct = 0\n",
    "    p_dic = {}\n",
    "    \n",
    "    for i in range(total_vals):\n",
    "        if PC[i] not in p_dic.keys():\n",
    "            p_dic[PC[i]] = np.zeros((n), dtype = 'int64')\n",
    "        current_vec = p_dic[PC[i]]\n",
    "        pred_val = Counter(current_vec).most_common(1)[0][0]\n",
    "        if pred_val == Val[i]:\n",
    "            correct +=1\n",
    "        else:\n",
    "            current_vec = current_vec[1:]\n",
    "            current_vec = np.append(current_vec, int(Val[i]))\n",
    "            p_dic[PC[i]] = current_vec\n",
    "    return (correct/total_vals)*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy for Global Load Value Predictor is 47.62\n"
     ]
    }
   ],
   "source": [
    "train_accu = last_n_vals(train_PC, train_MemAdd, train_Val, train_unique_PCs, train_unique_memadds, train_Val.shape[0], 5)\n",
    "print(\"The train accuracy for Global Load Value Predictor is {:.2f}\".format(train_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy for Global Load Value Predictor is 48.53\n"
     ]
    }
   ],
   "source": [
    "test_accu = last_n_vals(test_PC, test_MemAdd, test_Val, test_unique_PCs, test_unique_memadds, test_Val.shape[0], 5)\n",
    "print(\"The test accuracy for Global Load Value Predictor is {:.2f}\".format(test_accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor for Last n load values at perticular Memory Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_n_mem_vals(PC, MemAdd, Val, p, m, total_vals,n):\n",
    "    correct = 0\n",
    "    p_dic = {}\n",
    "    \n",
    "    for i in range(total_vals):\n",
    "        if (PC[i], MemAdd[i]) not in p_dic.keys():\n",
    "            p_dic[(PC[i], MemAdd[i])] = np.zeros((n), dtype = 'int64')\n",
    "        current_vec = p_dic[(PC[i], MemAdd[i])]\n",
    "        pred_val = Counter(current_vec).most_common(1)[0][0]\n",
    "        if pred_val == Val[i]:\n",
    "            correct +=1\n",
    "        else:\n",
    "            current_vec = current_vec[1:]\n",
    "            current_vec = np.append(current_vec, int(Val[i]))\n",
    "            p_dic[(PC[i], MemAdd[i])] = current_vec\n",
    "        \n",
    "    return (correct/total_vals)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy for Local Load Value Predictor 55.95\n"
     ]
    }
   ],
   "source": [
    "train_accu = last_n_mem_vals(train_PC, train_MemAdd, train_Val, train_unique_PCs, train_unique_memadds, train_Val.shape[0], 5)\n",
    "print(\"The train accuracy for Local Load Value Predictor {:.2f}\".format(train_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy for Local Load Value Predictor 56.94\n"
     ]
    }
   ],
   "source": [
    "test_accu = last_n_mem_vals(test_PC, test_MemAdd, test_Val, test_unique_PCs, test_unique_memadds, test_Val.shape[0], 5)\n",
    "print(\"The test accuracy for Local Load Value Predictor {:.2f}\".format(test_accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing unpredictable load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpredictable_loads(PC, MemAdd, Val, p, m, total_vals):\n",
    "    \n",
    "    max_checks = int(total_vals/p)\n",
    "    correct = 0\n",
    "    unpredictable_load_lst = []\n",
    "    skipped = 0\n",
    "    already_pred  = 0\n",
    "    p_dic = {}\n",
    "    p_lval_table = np.zeros((p,m), dtype = 'uint64')\n",
    "    for i in range(total_vals):\n",
    "        if PC[i] in unpredictable_load_lst:\n",
    "            skipped+=1\n",
    "            continue\n",
    "        else:\n",
    "            if PC[i] not in p_dic.keys():\n",
    "                p_dic[PC[i]] = [1]\n",
    "            if p_lval_table[PC[i]][MemAdd[i]] == Val[i]:\n",
    "                correct +=1\n",
    "                p_dic[PC[i]].append(1)\n",
    "            else:\n",
    "                p_lval_table[PC[i]][MemAdd[i]] = Val[i]\n",
    "                p_dic[PC[i]].append(0)\n",
    "            if p_dic[PC[i]].count(0) > max_checks:\n",
    "                unpredictable_load_lst.append(PC[i])\n",
    "                already_pred += len(p_dic[PC[i]])\n",
    "                \n",
    "    return (correct/(total_vals-skipped+already_pred))*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1654856104155,
     "user": {
      "displayName": "Bhagyesh Gaikwad",
      "userId": "02667505171407796611"
     },
     "user_tz": 420
    },
    "id": "_yaj9UIhF0yP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy for Predictable Loads Last Value Predictor  is 82.87\n"
     ]
    }
   ],
   "source": [
    "train_accu = unpredictable_loads(train_PC, train_MemAdd, train_Val, train_unique_PCs, train_unique_memadds, train_Val.shape[0])\n",
    "print(\"The train accuracy for Predictable Loads Last Value Predictor  is {:.2f}\".format(train_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy for Predictable Loads Last Value Predictor is 82.92\n"
     ]
    }
   ],
   "source": [
    "test_accu = unpredictable_loads(test_PC, test_MemAdd, test_Val, test_unique_PCs, test_unique_memadds, test_Val.shape[0])\n",
    "print(\"The test accuracy for Predictable Loads Last Value Predictor is {:.2f}\".format(test_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
